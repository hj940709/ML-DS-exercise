{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lemma': 270, 'surface': 'dummy_0', 'label': 9},\n",
       " {'lemma': 684, 'surface': 'dummy_1', 'label': 7},\n",
       " {'lemma': 806, 'surface': 'dummy_2', 'label': 0},\n",
       " {'lemma': 996, 'surface': 'dummy_3', 'label': 7},\n",
       " {'lemma': 109, 'surface': 'dummy_4', 'label': 6},\n",
       " {'lemma': 672, 'surface': 'dummy_5', 'label': 3},\n",
       " {'lemma': 773, 'surface': 'dummy_6', 'label': 7},\n",
       " {'lemma': 650, 'surface': 'dummy_7', 'label': 3},\n",
       " {'lemma': 265, 'surface': 'dummy_8', 'label': 4},\n",
       " {'lemma': 37, 'surface': 'dummy_9', 'label': 8},\n",
       " {'lemma': 496, 'surface': 'dummy_10', 'label': 4},\n",
       " {'lemma': 451, 'surface': 'dummy_11', 'label': 9},\n",
       " {'lemma': 37, 'surface': 'dummy_12', 'label': 2},\n",
       " {'lemma': 695, 'surface': 'dummy_13', 'label': 3},\n",
       " {'lemma': 526, 'surface': 'dummy_14', 'label': 7},\n",
       " {'lemma': 172, 'surface': 'dummy_15', 'label': 6},\n",
       " {'lemma': 558, 'surface': 'dummy_16', 'label': 1},\n",
       " {'lemma': 760, 'surface': 'dummy_17', 'label': 1},\n",
       " {'lemma': 276, 'surface': 'dummy_18', 'label': 1},\n",
       " {'lemma': 99, 'surface': 'dummy_19', 'label': 2}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dummy_generator(n=1000, length=20):\n",
    "    for _ in range(1000):\n",
    "        dummy_data = []\n",
    "        for i in range(length):\n",
    "            token={'lemma': int(np.random.uniform(1,1000)), 'surface': 'dummy_'+str(i), 'label': int(np.random.uniform(0,10))}\n",
    "            dummy_data.append(token)\n",
    "        yield dummy_data\n",
    "\n",
    "next(dummy_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 300)\n",
      "(?, ?, 30)\n",
      "(?, ?, 50, 300)\n",
      "(?, ?, 30)\n",
      "(?, ?, 360)\n",
      "(?, ?, 200)\n",
      "(?, ?, 11)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "charEntries = \" 0123456789abcdefghijklmnopqrstuvwxyzäöåABCDEFGHIJKLMNOPQRSTUVWXYZÄÖÅ\" + \\\n",
    "                \".,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|\\u2013\\u2014\\u201C\\u201D\"\n",
    "\n",
    "casingEntries = ['PADDING', 'other', 'numeric', 'mainly_numeric', 'allLower',\n",
    "                   'allUpper', 'mainly_allUpper', 'initialUpper', 'contains_upper',\n",
    "                   'contains_digit']\n",
    "charEmbedding = 'cnn'\n",
    "casingEntries= ['PADDING', 'other', 'numeric', 'mainly_numeric', 'allLower',\n",
    "               'allUpper', 'mainly_allUpper', 'initialUpper', 'contains_upper',\n",
    "               'contains_digit']\n",
    "labelEntries= ['B-PER', 'B-LOC', 'B-ORG', 'B-PRO', 'B-OTH',\n",
    "                'I-PER', 'I-LOC', 'I-ORG', 'I-PRO', 'I-OTH', 'O']\n",
    "classifier  = 'crf'\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    sentence_length= tf.placeholder(tf.int32, [None], name='sentence_length')\n",
    "\n",
    "    tokens_input = tf.placeholder(tf.int32, [None, None], name='words_input')\n",
    "    #W = tf.Variable(tf.constant(0.0, shape=[len(self.word2Idx), len(self.embeddings)], name=\"W_token\"), trainable=False)\n",
    "    W = tf.Variable(tf.random_uniform([10000, 300], -1.0, 1.0), name=\"W_char\")\n",
    "    embeddings = tf.placeholder(tf.float32, [10000, 300])\n",
    "    W.assign(embeddings)\n",
    "    tokens = tf.nn.embedding_lookup(W, tokens_input, name='tokens')\n",
    "    print(tokens.shape)\n",
    "\n",
    "    casing_input = tf.placeholder(tf.int32, [None, None],name='casing_input')\n",
    "    W = tf.Variable(tf.random_uniform([len(casingEntries), 30], -1.0, 1.0), name=\"W_case\")\n",
    "    casings = tf.nn.embedding_lookup(W, casing_input, name='casings')\n",
    "    print(casings.shape)\n",
    "\n",
    "    chars_input = tf.placeholder(tf.int32, [None, None, 50], name='char_input')\n",
    "    W = tf.Variable(tf.random_uniform([len(charEntries), 300], -1.0, 1.0), name=\"W_char\")\n",
    "    chars = tf.nn.embedding_lookup(W, chars_input, name='char_emd')\n",
    "    print(chars.shape)\n",
    "    if charEmbedding== 'lstm':\n",
    "        chars = tf.reshape(casings, [-1, 50, 300])\n",
    "        lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(30, name=\"char_fw_lstm\")\n",
    "        lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(30, name=\"char_bw_lstm\")\n",
    "        (output_fw, output_bw), _ = \\\n",
    "            tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, chars, dtype=tf.float32)\n",
    "        chars = tf.concat([output_fw, output_bw], axis=-1)\n",
    "        chars = tf.reshape(chars, [-1, tf.shape(chars_input)[-2], 60])\n",
    "    else:\n",
    "        chars = tf.layers.Conv2D(30, [1, 30], padding='same', name='char_cnn')(chars)\n",
    "        chars = tf.layers.MaxPooling2D([1, 50], strides=50, name=\"char_pooling\")(chars)\n",
    "        chars = tf.reshape(chars, [-1, tf.shape(chars_input)[-2], 30])\n",
    "    print(chars.shape)\n",
    "\n",
    "    label = tf.placeholder(tf.int32, [None, None, 1])\n",
    "    input_nodes = [tokens, casings, chars]\n",
    "    merged = tf.concat([_ for _ in input_nodes], axis=2)\n",
    "    print(merged.shape)\n",
    "    merged_input_shape = tf.shape(merged)\n",
    "    cnt = 1\n",
    "    for size in (100,100):\n",
    "        lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(size, name=\"merged_fw_lstm_\"+ str(cnt))\n",
    "        lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(size, name=\"merged_bw_lstm\" + str(cnt))\n",
    "        if isinstance((0.25,0.25), (list, tuple)):    \n",
    "            lstm_fw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_fw_cell, \n",
    "                                                         input_keep_prob=1 - 0.25,\n",
    "                                                         output_keep_prob=1 - 0.25)\n",
    "            lstm_bw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_bw_cell,\n",
    "                                                         input_keep_prob=1 - 0.25,\n",
    "                                                         output_keep_prob=1 - 0.25)\n",
    "            (output_fw, output_bw), _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, merged, sequence_length=sentence_length,\n",
    "                                           dtype=tf.float32)\n",
    "            merged = tf.concat([output_fw, output_bw], axis=-1)\n",
    "        cnt += 1\n",
    "\n",
    "    print(merged.shape)\n",
    "    merged = tf.reshape(merged, [-1, 200])\n",
    "    if classifier == 'softmax':\n",
    "        merged = tf.layers.Dense(len(labelEntries), activation=tf.nn.softmax, dtype=tf.float32)(merged)\n",
    "        merged = tf.reshape(merged, [-1, merged_input_shape[-2], 1, len(labelEntries)])\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=merged)\n",
    "        #output = tf.cast(tf.argmax(merged, axis=-1), tf.int32)\n",
    "    elif classifier == 'crf':\n",
    "        merged = tf.layers.Dense(len(labelEntries), name=\"hidden_lin_layer\")(merged)\n",
    "        merged = tf.reshape(merged, [-1, merged_input_shape[-2], len(labelEntries)])\n",
    "        log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(merged, tf.squeeze(label), sentence_length)\n",
    "        loss = -log_likelihood\n",
    "        print(merged.shape)\n",
    "        #output = np.array([tf.contrib.crf.viterbi_decode(_, transition_params) for _ in merged.eval()])\n",
    "   \n",
    "\n",
    "lossFct = tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \n",
    "\n",
    "precision = tf.metrics.precision(y_true, y_pred)\n",
    "recall = tf.metrics.recall(y_true, y_pred)\n",
    "f1_score = 2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-befca0326d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/contrib/crf/python/ops/crf.py\u001b[0m in \u001b[0;36mviterbi_decode\u001b[0;34m(score, transition_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrellis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtransition_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mtrellis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0mbackpointers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "print(transition_params.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
