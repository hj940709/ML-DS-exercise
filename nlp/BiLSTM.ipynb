{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lemma': 598, 'surface': 'dummy_0', 'label': 8},\n",
       " {'lemma': 606, 'surface': 'dummy_1', 'label': 3},\n",
       " {'lemma': 115, 'surface': 'dummy_2', 'label': 0},\n",
       " {'lemma': 495, 'surface': 'dummy_3', 'label': 1},\n",
       " {'lemma': 597, 'surface': 'dummy_4', 'label': 8},\n",
       " {'lemma': 958, 'surface': 'dummy_5', 'label': 0},\n",
       " {'lemma': 717, 'surface': 'dummy_6', 'label': 5},\n",
       " {'lemma': 579, 'surface': 'dummy_7', 'label': 8},\n",
       " {'lemma': 268, 'surface': 'dummy_8', 'label': 9},\n",
       " {'lemma': 899, 'surface': 'dummy_9', 'label': 2},\n",
       " {'lemma': 948, 'surface': 'dummy_10', 'label': 6},\n",
       " {'lemma': 675, 'surface': 'dummy_11', 'label': 3},\n",
       " {'lemma': 887, 'surface': 'dummy_12', 'label': 7},\n",
       " {'lemma': 48, 'surface': 'dummy_13', 'label': 9},\n",
       " {'lemma': 808, 'surface': 'dummy_14', 'label': 6},\n",
       " {'lemma': 840, 'surface': 'dummy_15', 'label': 1},\n",
       " {'lemma': 329, 'surface': 'dummy_16', 'label': 9},\n",
       " {'lemma': 328, 'surface': 'dummy_17', 'label': 5},\n",
       " {'lemma': 925, 'surface': 'dummy_18', 'label': 9},\n",
       " {'lemma': 238, 'surface': 'dummy_19', 'label': 9}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charEntries = \" 0123456789abcdefghijklmnopqrstuvwxyzäöåABCDEFGHIJKLMNOPQRSTUVWXYZÄÖÅ\" + \\\n",
    "                \".,-_()[]{}!?:;#'\\\"/\\\\%$`&=*+@^~|\\u2013\\u2014\\u201C\\u201D\"\n",
    "\n",
    "casingEntries = ['PADDING', 'other', 'numeric', 'mainly_numeric', 'allLower',\n",
    "                   'allUpper', 'mainly_allUpper', 'initialUpper', 'contains_upper',\n",
    "                   'contains_digit']\n",
    "charEmbedding = 'cnn'\n",
    "\n",
    "\n",
    "def dummy_generator(n=1000, length=20):\n",
    "    for _ in range(1000):\n",
    "        dummy_data = []\n",
    "        for i in range(length):\n",
    "            token={'lemma': int(np.random.uniform(1,1000)), 'surface': 'dummy_'+str(i), 'label': int(np.random.uniform(0,10))}\n",
    "            dummy_data.append(token)\n",
    "        yield dummy_data\n",
    "\n",
    "next(dummy_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 300)\n",
      "(?, ?, 30)\n",
      "(?, ?, 50, 300)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer char_cnn is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, None, 50, 300]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4f0418b8ff9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'char_cnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"char_pooling\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m                            \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m                            str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m   1478\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer char_cnn is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, None, 50, 300]"
     ]
    }
   ],
   "source": [
    "sentence_length= tf.placeholder(tf.int32, [None], name='sentence_length')\n",
    "\n",
    "tokens_input = tf.placeholder(tf.int32, [None, None], name='words_input')\n",
    "#W = tf.Variable(tf.constant(0.0, shape=[len(self.word2Idx), len(self.embeddings)], name=\"W_token\"), trainable=False)\n",
    "W = tf.Variable(tf.random_uniform([10000, 300], -1.0, 1.0), name=\"W_char\")\n",
    "embeddings = tf.placeholder(tf.float32, [10000, 300])\n",
    "W.assign(embeddings)\n",
    "tokens = tf.nn.embedding_lookup(W, tokens_input, name='tokens')\n",
    "print(tokens.shape)\n",
    "\n",
    "casing_input = tf.placeholder(tf.int32, [None, None],name='casing_input')\n",
    "W = tf.Variable(tf.random_uniform([len(casingEntries), 30], -1.0, 1.0), name=\"W_case\")\n",
    "casings = tf.nn.embedding_lookup(W, casing_input, name='casings')\n",
    "print(casings.shape)\n",
    "\n",
    "chars_input = tf.placeholder(tf.int32, [None, None, 50], name='char_input')\n",
    "W = tf.Variable(tf.random_uniform([len(charEntries), 300], -1.0, 1.0), name=\"W_char\")\n",
    "chars = tf.nn.embedding_lookup(W, chars_input, name='char_emd')\n",
    "print(chars.shape)\n",
    "if charEmbedding== 'lstm':\n",
    "    #chars = tf.boolean_mask(chars, np.array(chars[-1] != 1))\n",
    "    chars = tf.reshape(casings, [-1, chars_shape[-1], 50])\n",
    "    lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(30)\n",
    "    lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(30)\n",
    "    (output_fw, output_bw), _ = \\\n",
    "        tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, chars, dtype=tf.float32, name=\"char_lstm\")\n",
    "    chars = tf.concat([output_fw, output_bw], axis=-1)\n",
    "    \n",
    "else:\n",
    "    chars = tf.layers.Conv1D(30, 30, padding='same', name='char_cnn')(chars)\n",
    "    chars = tf.layers.MaxPooling1D(50, strides=1, name=\"char_pooling\")(chars)\n",
    "    chars = tf.reshape(casings, [-1, chars_shape[-1], 30])\n",
    "    #chars = tf.boolean_mask(chars, np.array(chars[-1] != 0))\n",
    "\n",
    "y_true = tf.placeholder(tf.int32, [None, 1])\n",
    "input_nodes = [tokens, casings, chars]\n",
    "merged_input = tf.concat([_[1] for _ in input_nodes], axis=1)\n",
    "\n",
    "merged = merged_input\n",
    "cnt = 1\n",
    "for size in (100,100):\n",
    "    lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(size)\n",
    "    lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(size)\n",
    "    if isinstance((0.25,0.25), (list, tuple)):\n",
    "        lstm_fw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_fw_cell,\n",
    "                                                     input_keep_prob=1 - 0.25,\n",
    "                                                     output_keep_prob=1 - 0.25)\n",
    "        lstm_bw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_bw_cell,\n",
    "                                                     input_keep_prob=1 - 0.25,\n",
    "                                                     output_keep_prob=1 - 0.25)\n",
    "        (output_fw, output_bw), _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell, lstm_bw_cell, merged,\n",
    "                                       dtype=tf.float32)\n",
    "        merged = tf.concat([output_fw, output_bw], axis=-1)\n",
    "    cnt += 1\n",
    "merged = tf.reshape(merged_input, [-1, s[-1], merged.shape[-1]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_3:0' shape=(1, 360) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
